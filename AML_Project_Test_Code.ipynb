{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "WyF9gUZ_ERtD",
   "metadata": {
    "id": "WyF9gUZ_ERtD"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EYiRWPXt7xN5",
   "metadata": {
    "id": "EYiRWPXt7xN5"
   },
   "source": [
    "# BUAN 6341 Project 1 - Group 5\n",
    "\n",
    "## Group Members\n",
    "\n",
    "- **Siva Srinivas Narra** (SXN230069)\n",
    "- **Prashanth Chowdary** (PXY230011)\n",
    "- **Tarun Raghu** (TXR230002)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y7LPZjvp-aKp",
   "metadata": {
    "id": "y7LPZjvp-aKp"
   },
   "source": [
    "# Project Overview\n",
    "\n",
    "## Goal\n",
    "Predict NVIDIA stock price will go up or down using historical prices, technical indicators, economic indicators, and company financials.\n",
    "\n",
    "## Why NVIDIA?\n",
    "NVIDIA is a leader in:\n",
    "- **Gaming:** Cutting-edge GPUs.\n",
    "- **AI & Machine Learning:** Pioneering advancements.\n",
    "- **Data Centers:** Powering cloud computing and big data.\n",
    "\n",
    "## Financial Performance\n",
    "NVIDIA shows strong revenue growth and solid profitability, making it an ideal subject for comprehensive analysis.\n",
    "\n",
    "### Objectives:\n",
    "- Analyze historical price trends.\n",
    "- Utilize technical indicators.\n",
    "- Examine economic indicators.\n",
    "- Evaluate company financials.\n",
    "\n",
    "Join us in exploring NVIDIA, a technological and market leader in the semiconductor industry.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i8o-Q095EV1X",
   "metadata": {
    "id": "i8o-Q095EV1X"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "APfWy_Y1CbRo",
   "metadata": {
    "id": "APfWy_Y1CbRo"
   },
   "source": [
    "## Step 1: Data Collection\n",
    "\n",
    "### Importing Hourly Stock Data for NVIDIA (NVDA)\n",
    "\n",
    "In this section, we will import the hourly stock data for NVIDIA (ticker: NVDA) from January 1, 2023, to July 1, 2024, using the `yfinance` library. The data will be stored in a DataFrame named `nvda_stock_data`.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "Zmx8AEg6F9R-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zmx8AEg6F9R-",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "c853decd-5a40-44f4-b77d-55a521c53ef3",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yfinance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myfinance\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01myf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime, timedelta\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define the stock and desired time frame\n",
    "ticker = \"NVDA\"\n",
    "end_date = datetime.today()\n",
    "start_date = end_date - timedelta(days=5*365)  # 5 years back from today\n",
    "interval = \"15m\"\n",
    "\n",
    "# Define the maximum period for each chunk (60 days)\n",
    "chunk_size = timedelta(days=55)\n",
    "\n",
    "# Initialize an empty list to store the DataFrame chunks\n",
    "data_chunks = []\n",
    "\n",
    "# Function to download and append data in chunks\n",
    "def download_stock_data(ticker, start_date, end_date, interval, chunk_size):\n",
    "    current_end_date = end_date\n",
    "    while current_end_date > start_date:\n",
    "        current_start_date = current_end_date - chunk_size\n",
    "        if current_start_date < start_date:\n",
    "            current_start_date = start_date\n",
    "        print(f\"Fetching data from {current_start_date} to {current_end_date}\")\n",
    "        chunk_data = yf.download(ticker, start=current_start_date, end=current_end_date, interval=interval)\n",
    "        if not chunk_data.empty:\n",
    "            chunk_data.reset_index(inplace=True)\n",
    "            chunk_data.columns = [f\"{ticker}_{col}\" if col != 'Datetime' else col for col in chunk_data.columns]\n",
    "            chunk_data['Datetime_conv'] = chunk_data['Datetime'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            data_chunks.append(chunk_data)\n",
    "        current_end_date = current_start_date\n",
    "\n",
    "# Download data in chunks\n",
    "download_stock_data(ticker, start_date, end_date, interval, chunk_size)\n",
    "\n",
    "# Combine all chunks into a single DataFrame\n",
    "nvda_stock_data = pd.concat(data_chunks, ignore_index=True)\n",
    "\n",
    "# Display the NVIDIA's stock data\n",
    "print(f\"\\n15-minute interval data for {ticker} for the last 5 years has been imported and stored in nvda_stock_data.\")\n",
    "\n",
    "# Show the first 3 rows of the DataFrame\n",
    "print(nvda_stock_data.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7FkzW5bbTXGh",
   "metadata": {
    "id": "7FkzW5bbTXGh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "nv7mt0BdRRod",
   "metadata": {
    "id": "nv7mt0BdRRod"
   },
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qVUUwTUgSW-O",
   "metadata": {
    "id": "qVUUwTUgSW-O"
   },
   "source": [
    "### Analyzing the Competitive Impact on NVIDIA's Stock Price\n",
    "\n",
    "NVIDIA's stock price is significantly influenced by its competitive environment. Key competitors such as Intel, AMD, Google, and Qualcomm can impact NVIDIA’s market share and investor sentiment through their performance and innovation. Therefore, it’s important for investors to closely monitor these companies.\n",
    "\n",
    "In this section, we will download the historical hourly stock price data for these competitors over the same time frame as NVIDIA. This will help us understand how changes in the competitive landscape might affect NVIDIA's stock price.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493b968a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "493b968a",
    "outputId": "a2ba098b-60bc-469b-e716-8fad466f7468"
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Define the list of companies and their stock symbols\n",
    "companies = {\n",
    "    \"Intel\": \"INTC\",\n",
    "    \"AMD\": \"AMD\",\n",
    "    \"Google\": \"GOOGL\",\n",
    "    \"Qualcomm\": \"QCOM\"\n",
    "}\n",
    "# Set the start date and end date for fetching the data\n",
    "start_date = '2023-01-01'\n",
    "end_date = '2024-07-01'\n",
    "\n",
    "# Dictionary to store DataFrames\n",
    "company_data = {}\n",
    "\n",
    "for company, symbol in companies.items():\n",
    "    # Fetch the hourly stock data for the specified date range\n",
    "    stock_data = yf.download(symbol, start=start_date, end=end_date, interval='1h')\n",
    "\n",
    "    # Rename columns with company name as prefix\n",
    "    stock_data.columns = [f\"{company}_{col}\" for col in stock_data.columns]\n",
    "\n",
    "    # Store the DataFrame in the dictionary\n",
    "    company_data[company] = stock_data\n",
    "\n",
    "print(\"\\n Hourly data for Intel, AMD, Google, Qualcomm from 2023-01-01 to 2024-07-01 has been imported and stored.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vSiO8QdpjINk",
   "metadata": {
    "id": "vSiO8QdpjINk"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IT_Fw3IWhINm",
   "metadata": {
    "id": "IT_Fw3IWhINm"
   },
   "source": [
    "### Accessing and Displaying Competitor Stock Data\n",
    "\n",
    "In this section, we retrieve and display the hourly stock data for each competitor. To facilitate identification, each column in the data is prefixed with the company name. This allows for easy differentiation between the data of various competitors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a08ba91",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "1a08ba91",
    "outputId": "36e76389-e8c1-40fa-98c0-ee87095120db"
   },
   "outputs": [],
   "source": [
    "# Accessing Intel's stock data and resetting the index\n",
    "intel_data = company_data[\"Intel\"]\n",
    "intel_data.reset_index(inplace=True)\n",
    "\n",
    "# Displaying the first few rows of Intel's stock data\n",
    "print(\"\\nIntel Stock Data:\")\n",
    "intel_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4QQZ1fWPIbWt",
   "metadata": {
    "id": "4QQZ1fWPIbWt"
   },
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cpnYo6PvGtOn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "cpnYo6PvGtOn",
    "outputId": "dd4f2f8c-0244-41a1-b799-fc14814e6356"
   },
   "outputs": [],
   "source": [
    "# Accessing AMD's stock data and resetting the index\n",
    "amd_data = company_data[\"AMD\"]\n",
    "amd_data.reset_index(inplace=True)\n",
    "\n",
    "# Displaying the first few rows of AMD's stock data\n",
    "print(\"\\nAMD Stock Data:\")\n",
    "amd_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "omTL_BnBIfOT",
   "metadata": {
    "id": "omTL_BnBIfOT"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5T_vIoMZGyo-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "5T_vIoMZGyo-",
    "outputId": "b4d04e4f-ad4a-498c-b242-e0df1446095f"
   },
   "outputs": [],
   "source": [
    "# Accessing Qualcomm's stock data and resetting the index\n",
    "qcom_data = company_data[\"Qualcomm\"]\n",
    "qcom_data.reset_index(inplace=True)\n",
    "\n",
    "# Displaying the first few rows of Qualcomm's stock data\n",
    "print(\"\\nQualcomm Stock Data:\")\n",
    "qcom_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ToNWv6xmIiK3",
   "metadata": {
    "id": "ToNWv6xmIiK3"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BcP4qUOQG3E_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "BcP4qUOQG3E_",
    "outputId": "0d853df8-fc5a-42b3-addd-72503921bf08"
   },
   "outputs": [],
   "source": [
    "# Accessing Google's stock data and resetting the index\n",
    "google_data = company_data[\"Google\"]\n",
    "google_data.reset_index(inplace=True)\n",
    "\n",
    "# Displaying the first few rows of Google's stock data\n",
    "print(\"\\nGoogle Stock Data:\")\n",
    "google_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dUS8nGqSkiT1",
   "metadata": {
    "id": "dUS8nGqSkiT1"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buL6Lp8RpRfU",
   "metadata": {
    "id": "buL6Lp8RpRfU"
   },
   "source": [
    "### Combining Competitor Data with NVIDIA Stock Data\n",
    "\n",
    "This section merges the stock data of Intel, AMD, Qualcomm, and Google with NVIDIA's stock data. The merge is performed using a left join on the `Datetime` column, appending each company's data horizontally to NVIDIA's data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AIhhSYxFot8d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 842
    },
    "id": "AIhhSYxFot8d",
    "outputId": "54fc1dbc-9686-4d67-a175-3d2ab6587355"
   },
   "outputs": [],
   "source": [
    "# Ensuring the datetime columns are in the same format by removing timezone information\n",
    "nvda_stock_data['Datetime'] = nvda_stock_data['Datetime'].dt.tz_localize(None)\n",
    "intel_data['Datetime'] = intel_data['Datetime'].dt.tz_localize(None)\n",
    "amd_data['Datetime'] = amd_data['Datetime'].dt.tz_localize(None)\n",
    "qcom_data['Datetime'] = qcom_data['Datetime'].dt.tz_localize(None)\n",
    "google_data['Datetime'] = google_data['Datetime'].dt.tz_localize(None)\n",
    "\n",
    "merged_data = nvda_stock_data.merge(intel_data, on='Datetime', how='left', suffixes=('', '_Intel'))\n",
    "merged_data = merged_data.merge(amd_data, on='Datetime', how='left', suffixes=('', '_AMD'))\n",
    "merged_data = merged_data.merge(qcom_data, on='Datetime', how='left', suffixes=('', '_Qualcomm'))\n",
    "merged_data = merged_data.merge(google_data, on='Datetime', how='left', suffixes=('', '_Google'))\n",
    "\n",
    "# Displaying the first few rows of merged stock data\n",
    "print(\"\\nMerged Data:\")\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hgl-eAazIsfr",
   "metadata": {
    "id": "hgl-eAazIsfr"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8zfcaKcPi6ZJ",
   "metadata": {
    "id": "8zfcaKcPi6ZJ"
   },
   "source": [
    "### Applying Key Technical Indicators to Stock Data\n",
    "\n",
    "In this section, we calculate and add key technical indicators to the `stock_data` DataFrame to enhance stock price analysis. Below is an overview of some of the indicators used:\n",
    "\n",
    "1. **Moving Averages (SMA and EMA)**\n",
    "   - **Simple Moving Average (SMA):** Computes the average closing price over a specified period (e.g., 20 days). SMA helps smooth out price data to identify overall trends.\n",
    "   - **Exponential Moving Average (EMA):** Calculates a weighted average of the closing price, giving more importance to recent prices. EMA responds more quickly to price changes compared to SMA, highlighting recent trends.\n",
    "\n",
    "2. **Moving Average Convergence Divergence (MACD)**\n",
    "   - **Description:** Computes the MACD line and the MACD signal line. The MACD helps identify changes in trend strength, direction, momentum, and duration. It provides signals for potential buy or sell opportunities.\n",
    "\n",
    "3. **Relative Strength Index (RSI)**\n",
    "   - **Description:** Calculates the RSI over a specified period (e.g., 14 days). RSI measures the speed and change of price movements to identify overbought or oversold conditions, indicating potential reversal points.\n",
    "\n",
    "4. **Bollinger Bands**\n",
    "   - **Description:** Uses the Simple Moving Average (SMA) and calculates two outer bands at a specified number of standard deviations from the SMA. Bollinger Bands help assess market volatility and identify potential price reversals by showing the range in which prices typically move.\n",
    "\n",
    "These indicators along with other indicators are integrated into the `nvda_stock_data` DataFrame to provide insights into price movements, trends, and volatility. Utilizing these technical indicators helps in making more informed trading decisions and understanding the stock's performance better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9783fa8a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9783fa8a",
    "outputId": "9b76bdbc-2b68-46be-91bc-39a97ae30d04"
   },
   "outputs": [],
   "source": [
    "!pip install pandas_ta\n",
    "import pandas_ta as ta\n",
    "import pandas as pd\n",
    "\n",
    "# Simple Moving Average (SMA) over a 20-day period\n",
    "merged_data['NVDA_SMA_20'] = ta.sma(merged_data['NVDA_Close'], length=20)\n",
    "\n",
    "# Exponential Moving Average (EMA) over a 20-day period\n",
    "merged_data['NVDA_EMA_20'] = ta.ema(merged_data['NVDA_Close'], length=20)\n",
    "\n",
    "# Moving Average Convergence Divergence (MACD)\n",
    "merged_data['NVDA_MACD'], merged_data['NVDA_MACD_signal'], _ = ta.macd(merged_data['NVDA_Close'])\n",
    "\n",
    "# Relative Strength Index (RSI) over a 14-day period\n",
    "merged_data['NVDA_RSI'] = ta.rsi(merged_data['NVDA_Close'], length=14)\n",
    "\n",
    "# Bollinger Bands\n",
    "bbands = ta.bbands(merged_data['NVDA_Close'])\n",
    "bbands.columns = [f'NVDA_{col}' for col in bbands.columns]\n",
    "merged_data = pd.concat([merged_data, bbands], axis=1)\n",
    "\n",
    "# Average True Range (ATR)\n",
    "merged_data['NVDA_ATR'] = ta.atr(merged_data['NVDA_High'], merged_data['NVDA_Low'], merged_data['NVDA_Close'])\n",
    "\n",
    "# On-Balance Volume (OBV)\n",
    "merged_data['NVDA_OBV'] = ta.obv(merged_data['NVDA_Close'], merged_data['NVDA_Volume'])\n",
    "\n",
    "# Stochastic Oscillator (Stoch)\n",
    "stoch_data = ta.stoch(merged_data['NVDA_High'], merged_data['NVDA_Low'], merged_data['NVDA_Close'])\n",
    "stoch_data.columns = [f'NVDA_{col}' for col in stoch_data.columns]\n",
    "merged_data = pd.concat([merged_data, stoch_data], axis=1)\n",
    "\n",
    "envelope_percentage = 2 / 100\n",
    "\n",
    "# Calculate the upper and lower envelopes\n",
    "merged_data['NVDA_EMA_Upper'] = merged_data['NVDA_EMA_20'] * (1 + envelope_percentage)\n",
    "merged_data['NVDA_EMA_Lower'] = merged_data['NVDA_EMA_20'] * (1 - envelope_percentage)\n",
    "\n",
    "# Calculate Money Flow Multiplier\n",
    "merged_data['MFM'] = ((merged_data['NVDA_Close'] - merged_data['NVDA_Low']) - (merged_data['NVDA_High'] - merged_data['NVDA_Close'])) / (merged_data['NVDA_High'] - merged_data['NVDA_Low'])\n",
    "\n",
    "# Calculate Money Flow Volume\n",
    "merged_data['MFV'] = merged_data['MFM'] * merged_data['NVDA_Volume']\n",
    "\n",
    "# Calculate CMF for a specific period (e.g., 20 days)\n",
    "period = 20\n",
    "merged_data['NVDA_CMF'] = merged_data['MFV'].rolling(window=period).sum() / merged_data['NVDA_Volume'].rolling(window=period).sum()\n",
    "\n",
    "# Drop intermediate columns\n",
    "merged_data.drop(columns=['MFM', 'MFV'], inplace=True)\n",
    "\n",
    "# Calculate the Typical Price\n",
    "merged_data['Typical_Price'] = (merged_data['NVDA_High'] + merged_data['NVDA_Low'] + merged_data['NVDA_Close']) / 3\n",
    "\n",
    "# Calculate the VWAP\n",
    "merged_data['Cumulative_TP_Volume'] = (merged_data['Typical_Price'] * merged_data['NVDA_Volume']).cumsum()\n",
    "merged_data['Cumulative_Volume'] = merged_data['NVDA_Volume'].cumsum()\n",
    "merged_data['NVDA_VWAP'] = merged_data['Cumulative_TP_Volume'] / merged_data['Cumulative_Volume']\n",
    "\n",
    "# Drop intermediate columns\n",
    "merged_data.drop(columns=['Typical_Price', 'Cumulative_TP_Volume', 'Cumulative_Volume'], inplace=True)\n",
    "\n",
    "# Create 'Date' column containing only date information\n",
    "merged_data['Date'] = merged_data['Datetime'].dt.date\n",
    "\n",
    "merged_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XfXI60hcIy7K",
   "metadata": {
    "id": "XfXI60hcIy7K"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GmJiWe7kKVhq",
   "metadata": {
    "id": "GmJiWe7kKVhq"
   },
   "source": [
    "## Economic Indicator Data Fetching and Analysis\n",
    "\n",
    "This section aims to fetch key economic indicators from the Federal Reserve Economic Data (FRED) and combine them into a single DataFrame for analysis. The indicators include the Federal Funds Rate, Consumer Price Index for All Urban Consumers, Real Gross Domestic Product, and Unemployment Rate.\n",
    "\n",
    "### Economic Indicators Explained\n",
    "\n",
    "1. **Federal Funds Rate (FEDFUNDS)**:\n",
    "    - The interest rate at which depository institutions trade federal funds (balances held at Federal Reserve Banks) with each other overnight. This rate influences other interest rates, such as for mortgages, loans, and savings, and is a key tool used by the Federal Reserve to control monetary policy.\n",
    "\n",
    "2. **Consumer Price Index for All Urban Consumers (CPIAUCNS)**:\n",
    "    - A measure of the average change over time in the prices paid by urban consumers for a market basket of consumer goods and services. It is a widely used indicator of inflation, reflecting the cost of living and purchasing power of consumers.\n",
    "\n",
    "3. **Real Gross Domestic Product (GDP)**:\n",
    "    - The total value of all goods and services produced in a country, adjusted for inflation. It provides a comprehensive overview of economic activity and health, indicating how well the economy is performing. Real GDP is used to compare the economic performance of different periods.\n",
    "\n",
    "4. **Unemployment Rate (UNRATE)**:\n",
    "    - The percentage of the total labor force that is unemployed but actively seeking employment and willing to work. It is a key indicator of labor market health and economic stability, influencing consumer spending and economic growth.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mOlndMeMrXRq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "mOlndMeMrXRq",
    "outputId": "166668d5-155e-4e47-8ef1-57e2d7955c5a"
   },
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the time period with correct date format\n",
    "start_date = datetime(2023, 1, 1)\n",
    "end_date = datetime(2024, 7, 1)\n",
    "\n",
    "# Define the data series you want to download\n",
    "data_series = {\n",
    "    'FEDFUNDS': 'FEDFUNDS',          # Federal Funds Rate\n",
    "    'CPIAUCNS': 'CPIAUCNS',         # Consumer Price Index for All Urban Consumers\n",
    "    'GDP': 'GDP',                  # Real Gross Domestic Product\n",
    "    'UNRATE': 'UNRATE'         # Unemployment Rate\n",
    "}\n",
    "\n",
    "# Fetch the data\n",
    "data = {}\n",
    "for name, code in data_series.items():\n",
    "    try:\n",
    "        data[name] = pdr.get_data_fred(code, start_date, end_date)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {name}: {e}\")\n",
    "\n",
    "# Combine all data into a single DataFrame\n",
    "economic_df = pd.concat(data.values(), axis=1, keys=data.keys())\n",
    "\n",
    "# Flatten the MultiIndex columns and rename to the desired names\n",
    "economic_df.columns = [col[0] for col in economic_df.columns]\n",
    "\n",
    "# Rename columns to the specified names\n",
    "economic_df.columns = [name for name in data_series.keys()]\n",
    "\n",
    "economic_df.reset_index(inplace=True)\n",
    "economic_df['DATE'] = economic_df['DATE'].dt.strftime('%Y_%m_%d')\n",
    "# Display the first few rows of the combined dataset\n",
    "print(\"\\nEconomic Indicator Data:\")\n",
    "economic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kCNxFbMEI3HD",
   "metadata": {
    "id": "kCNxFbMEI3HD"
   },
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R6NupLG9LLpf",
   "metadata": {
    "id": "R6NupLG9LLpf"
   },
   "source": [
    "In the code below, the fetched economic indicator data is joined with historical stock price data at the month and year level granularity. This allows for a comprehensive analysis of how these economic indicators impact the stock price over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dDUUksuht4KP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 842
    },
    "id": "dDUUksuht4KP",
    "outputId": "0aa9e568-cfb7-41b5-eb82-964cfd320480"
   },
   "outputs": [],
   "source": [
    "# Convert 'Date' in merged_data to datetime\n",
    "merged_data['Date'] = pd.to_datetime(merged_data['Date'], format='%Y_%m_%d')\n",
    "\n",
    "# Convert 'DATE' in economic_df to datetime\n",
    "economic_df['DATE'] = pd.to_datetime(economic_df['DATE'], format='%Y_%m_%d')\n",
    "\n",
    "# Extract year and month from 'Date' column in merged_data\n",
    "merged_data['Year'] = merged_data['Date'].dt.year\n",
    "merged_data['Month'] = merged_data['Date'].dt.month\n",
    "\n",
    "# Extract year and month from 'DATE' column in economic_df\n",
    "economic_df['Year'] = economic_df['DATE'].dt.year\n",
    "economic_df['Month'] = economic_df['DATE'].dt.month\n",
    "\n",
    "# Merge on 'Year' and 'Month'\n",
    "merged_data = merged_data.merge(economic_df, on=['Year', 'Month'], how='left')\n",
    "\n",
    "# Display the first few rows of the final dataset\n",
    "print(\"\\nFinal Merged Data:\")\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CUDnVLOEI6K9",
   "metadata": {
    "id": "CUDnVLOEI6K9"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sh6QqdchPJJW",
   "metadata": {
    "id": "sh6QqdchPJJW"
   },
   "source": [
    "### Impact of the NVIDIA Income Statement on Stock Price\n",
    "\n",
    "The income statment is crucial for stock price movements:\n",
    "\n",
    "- **Profitability Metrics**: Strong profits and revenue growth can boost stock prices.\n",
    "- **Investment Decisions**: Positive financial results attract investors and can drive up stock prices.\n",
    "- **Market Perception**: Good earnings reports improve market confidence, impacting stock prices.\n",
    "- **Comparative Analysis**: Comparing financial performance with peers helps investors assess stock value.\n",
    "\n",
    "NVIDIA's quarterly income statement affects investor perceptions and stock price through its financial performance.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e172db86",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "e172db86",
    "outputId": "af02a981-ba04-4076-9370-7da66a2a18e9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# Define the ticker symbol for NVIDIA\n",
    "ticker_symbol = 'NVDA'\n",
    "\n",
    "# Fetch NVIDIA's financial data\n",
    "nvidia_data = yf.Ticker(ticker_symbol)\n",
    "\n",
    "# Get NVIDIA's quarterly income statement\n",
    "quarterly_income_statement = nvidia_data.quarterly_financials\n",
    "\n",
    "# Reset the index to turn the row indices into a column\n",
    "pivoted_income_statement = quarterly_income_statement.reset_index()\n",
    "\n",
    "# Pivot the DataFrame to have metrics as columns\n",
    "pivoted_income_statement = pivoted_income_statement.melt(id_vars='index', var_name='Date', value_name='Amount')\n",
    "pivoted_income_statement.columns = ['Metric', 'Date', 'Amount']\n",
    "\n",
    "# Pivot the melted DataFrame so that metrics are columns\n",
    "pivoted_income_statement = pivoted_income_statement.pivot_table(index='Date', columns='Metric', values='Amount')\n",
    "\n",
    "# Reset index to make 'Date' a column again\n",
    "pivoted_income_statement.reset_index(inplace=True)\n",
    "\n",
    "# Print the pivoted income statement\n",
    "print(\"NVIDIA Quarterly Income Statement:\")\n",
    "pivoted_income_statement  # Print the first few rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QLh1kb5FkL-i",
   "metadata": {
    "id": "QLh1kb5FkL-i"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QEb7moQJQStF",
   "metadata": {
    "id": "QEb7moQJQStF"
   },
   "source": [
    "In the code below, the fetched income statement is joined with historical stock price data at the quarter and year level granularity. This allows for a comprehensive analysis of how income statement impacts the stock price over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pwKm5Q2FM7L-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 894
    },
    "id": "pwKm5Q2FM7L-",
    "outputId": "a1b1953b-299b-4e25-bac5-c14bbc3f1474"
   },
   "outputs": [],
   "source": [
    "# Convert 'Date' in merged_data to datetime\n",
    "merged_data['Date'] = pd.to_datetime(merged_data['Date'], format='%Y_%m_%d')\n",
    "\n",
    "# Convert 'DATE' in economic_df to datetime\n",
    "pivoted_income_statement['Date'] = pd.to_datetime(pivoted_income_statement['Date'], format='%Y_%m_%d')\n",
    "\n",
    "# Extract year and quarter from 'Date' column in merged_data\n",
    "merged_data['Year'] = merged_data['Date'].dt.year\n",
    "merged_data['Quarter'] = merged_data['Date'].dt.quarter\n",
    "\n",
    "# Extract year and quarter from 'Date' column in pivoted_income_statement\n",
    "pivoted_income_statement['Year'] = pivoted_income_statement['Date'].dt.year\n",
    "pivoted_income_statement['Quarter'] = pivoted_income_statement['Date'].dt.quarter\n",
    "\n",
    "# Merge on 'Year' and 'Quarter'\n",
    "merged_data = merged_data.merge(pivoted_income_statement, on=['Year', 'Quarter'], how='left')\n",
    "\n",
    "# Display the first few rows of the final dataset\n",
    "print(\"\\nFinal Merged Data:\")\n",
    "merged_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PLTSOP17kOuW",
   "metadata": {
    "id": "PLTSOP17kOuW"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5oTTZZJk57v",
   "metadata": {
    "id": "d5oTTZZJk57v"
   },
   "source": [
    "### Impact of the NVIDIA Balance Sheet on Stock Price\n",
    "\n",
    "The balance sheet is crucial for stock price movements:\n",
    "\n",
    "- **Liquidity Metrics**: High levels of cash and liquid assets indicate strong liquidity, which can positively impact stock prices.\n",
    "- **Debt Levels**: Lower debt levels and manageable debt ratios are seen as favorable, reducing financial risk and potentially boosting stock prices.\n",
    "- **Asset Management**: Efficient use of assets to generate revenue and profit enhances investor confidence, influencing stock prices.\n",
    "- **Equity Value**: Strong shareholder equity reflects financial stability and growth potential, which can drive up stock prices.\n",
    "\n",
    "NVIDIA's quarterly balance sheet affects investor perceptions and stock price through its financial health and stability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ds2xlmKMvasB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "id": "ds2xlmKMvasB",
    "outputId": "5b360abe-9be7-4126-91d6-f4c17f5d7161"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# Define the ticker symbol for NVIDIA\n",
    "ticker_symbol = 'NVDA'\n",
    "\n",
    "# Fetch NVIDIA's financial data\n",
    "nvidia_data = yf.Ticker(ticker_symbol)\n",
    "\n",
    "# Get NVIDIA's quarterly balance sheet\n",
    "quarterly_balance_sheet = nvidia_data.quarterly_balance_sheet\n",
    "\n",
    "# Reset the index to turn the row indices into a column\n",
    "pivoted_balance_sheet = quarterly_balance_sheet.reset_index()\n",
    "\n",
    "# Melt the DataFrame to have metrics as rows\n",
    "pivoted_balance_sheet = pivoted_balance_sheet.melt(id_vars='index', var_name='Date', value_name='Amount')\n",
    "pivoted_balance_sheet.columns = ['Metric', 'Date', 'Amount']\n",
    "\n",
    "# Pivot the melted DataFrame so that metrics are columns\n",
    "pivoted_balance_sheet = pivoted_balance_sheet.pivot_table(index='Date', columns='Metric', values='Amount')\n",
    "\n",
    "# Reset index to make 'Date' a column again\n",
    "pivoted_balance_sheet.reset_index(inplace=True)\n",
    "\n",
    "# Print the pivoted balance sheet\n",
    "print(\"NVIDIA Quarterly Balance Sheet with Metrics as Columns:\")\n",
    "pivoted_balance_sheet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R0-C4DUVlix7",
   "metadata": {
    "id": "R0-C4DUVlix7"
   },
   "source": [
    "In the code below, the fetched balance sheet is joined with historical stock price data at the quarter and year level granularity. This allows for a comprehensive analysis of how balance sheet impacts the stock price over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wu3u9a3FvavJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 894
    },
    "id": "wu3u9a3FvavJ",
    "outputId": "9a01b663-6dd3-4e33-9303-5ff3dc8403d3"
   },
   "outputs": [],
   "source": [
    "# Convert 'DATE' in pivoted_balance_sheet to datetime\n",
    "pivoted_balance_sheet['Date'] = pd.to_datetime(pivoted_balance_sheet['Date'], format='%Y_%m_%d')\n",
    "\n",
    "# Extract year and quarter from 'Date' column in pivoted_balance_sheet\n",
    "pivoted_balance_sheet['Year'] = pivoted_balance_sheet['Date'].dt.year\n",
    "pivoted_balance_sheet['Quarter'] = pivoted_balance_sheet['Date'].dt.quarter\n",
    "\n",
    "# Merge on 'Year' and 'Quarter'\n",
    "merged_data = merged_data.merge(pivoted_balance_sheet, on=['Year', 'Quarter'], how='left')\n",
    "\n",
    "# Display the first few rows of the final dataset\n",
    "print(\"\\nFinal Merged Data:\")\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alMUQYxplLhD",
   "metadata": {
    "id": "alMUQYxplLhD"
   },
   "source": [
    "### Impact of the NVIDIA Cash Flow Statement on Stock Price\n",
    "\n",
    "The cash flow statement is crucial for stock price movements:\n",
    "\n",
    "- **Operating Cash Flow**: Strong operating cash flow indicates robust core business performance, which can positively impact stock prices.\n",
    "- **Investment Activities**: Cash used or generated from investment activities provides insight into future growth prospects, influencing stock prices.\n",
    "- **Financing Activities**: Effective management of cash from financing activities, such as debt repayment or share repurchases, can enhance investor confidence and impact stock prices.\n",
    "- **Free Cash Flow**: High free cash flow signifies the company's ability to generate surplus cash, which can be used for expansion, dividends, or reducing debt, potentially boosting stock prices.\n",
    "\n",
    " NVIDIA's quarterly cash flow statement affects investor perceptions and stock price through its cash management and overall financial health.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AfM7D0ASkU7G",
   "metadata": {
    "id": "AfM7D0ASkU7G"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muwlBX9jvayQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "muwlBX9jvayQ",
    "outputId": "0d4fef75-7697-46ee-d865-ef8f95138629"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# Define the ticker symbol for NVIDIA\n",
    "ticker_symbol = 'NVDA'\n",
    "\n",
    "# Fetch NVIDIA's financial data\n",
    "nvidia_data = yf.Ticker(ticker_symbol)\n",
    "\n",
    "# Get NVIDIA's quarterly cash flow statement\n",
    "quarterly_cash_flow = nvidia_data.quarterly_cashflow\n",
    "\n",
    "# Reset the index to turn the row indices into a column\n",
    "pivoted_cash_flow = quarterly_cash_flow.reset_index()\n",
    "\n",
    "# Melt the DataFrame to have metrics as rows\n",
    "pivoted_cash_flow = pivoted_cash_flow.melt(id_vars='index', var_name='Date', value_name='Amount')\n",
    "pivoted_cash_flow.columns = ['Metric', 'Date', 'Amount']\n",
    "\n",
    "# Pivot the melted DataFrame so that metrics are columns\n",
    "pivoted_cash_flow = pivoted_cash_flow.pivot_table(index='Date', columns='Metric', values='Amount')\n",
    "\n",
    "# Reset index to make 'Date' a column again\n",
    "pivoted_cash_flow.reset_index(inplace=True)\n",
    "\n",
    "# Print the pivoted cash flow statement\n",
    "print(\"NVIDIA Quarterly Cash Flow Statement with Metrics as Columns:\")\n",
    "pivoted_cash_flow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bwJ_4cl02v",
   "metadata": {
    "id": "d8bwJ_4cl02v"
   },
   "source": [
    "In the code below, the fetched cash flow  is joined with historical stock price data at the quarter and year level granularity. This allows for a comprehensive analysis of how cash flow impacts the stock price over time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auTCBcMkva1I",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "auTCBcMkva1I",
    "outputId": "3770a80a-94fc-4819-ec19-4d479e198335"
   },
   "outputs": [],
   "source": [
    "# Convert 'DATE' in pivoted_cash_flow to datetime\n",
    "pivoted_cash_flow['Date'] = pd.to_datetime(pivoted_cash_flow['Date'], format='%Y_%m_%d')\n",
    "\n",
    "# Extract year and quarter from 'Date' column in pivoted_cash_flow\n",
    "pivoted_cash_flow['Year'] = pivoted_cash_flow['Date'].dt.year\n",
    "pivoted_cash_flow['Quarter'] = pivoted_cash_flow['Date'].dt.quarter\n",
    "\n",
    "# Merge on 'Year' and 'Quarter', specifying suffixes to avoid duplicates\n",
    "merged_data = merged_data.merge(pivoted_cash_flow, on=['Year', 'Quarter'], how='left', suffixes=('_existing', '_cashflow'))\n",
    "\n",
    "# Display the first few rows of the final dataset\n",
    "print(\"\\nFinal Merged Data:\")\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PJ_lT02IqvB5",
   "metadata": {
    "id": "PJ_lT02IqvB5"
   },
   "source": [
    "### Step 2: Data Preparation\n",
    "\n",
    "In this step, we will focus on data quality checks followed by data cleaning tasks. As part of the data quality checks, we will list all the variables along with their descriptions and data types. We will also examine sample values from each variable. Our dataset does not contain categorical variables but includes many numerical variables. We will choose 5 numerical variables. We will check the following information for each variable:\n",
    "\n",
    "1. Number of observations in the variable\n",
    "2. Range of the variable\n",
    "3. Minimum and Maximum of the variable\n",
    "4. Mean and standard deviation/variance of the variable\n",
    "5. Mode, median, and quartiles\n",
    "6. Histogram of the variable\n",
    "7. Any interesting findings\n",
    "\n",
    "Below is the Python code to perform these checks and generate the required statistics and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OASwcTgMuA_X",
   "metadata": {
    "id": "OASwcTgMuA_X"
   },
   "outputs": [],
   "source": [
    "# Function to generate summary report of DataFrame variables\n",
    "def summarize_dataframe(df):\n",
    "    # Initialize an empty list to store summary data\n",
    "    summary = []\n",
    "\n",
    "    # Iterate over each column in the DataFrame\n",
    "    for column in df.columns:\n",
    "        # Get data type of the variable\n",
    "        dtype = df[column].dtype\n",
    "\n",
    "        # Handle cases where there are no non-null values\n",
    "        if df[column].dropna().size > 0:\n",
    "            non_null_values = df[column].dropna().sample(n=5, random_state=1).tolist()\n",
    "        else:\n",
    "            non_null_values = \"No non-null values\"  # Indicate no non-null values\n",
    "\n",
    "        # Add the summary data to the list\n",
    "        summary.append({\n",
    "            'Variable': column,\n",
    "            'Data Type': dtype,\n",
    "            'Sample Values': non_null_values\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame from the summary data\n",
    "    summary_df = pd.DataFrame(summary)\n",
    "\n",
    "    return summary_df\n",
    "\n",
    "# Generate the summary report\n",
    "summary_report = summarize_dataframe(merged_data)\n",
    "\n",
    "# Display the summary report\n",
    "summary_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TEYA8KmHA5m1",
   "metadata": {
    "id": "TEYA8KmHA5m1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def analyze_numeric_variable(df, column):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Column {column} does not exist in the DataFrame.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n### Analysis for {column} ###\")\n",
    "\n",
    "    # Number of observations\n",
    "    num_obs = df[column].count()\n",
    "    print(f\"Number of observations: {num_obs}\")\n",
    "\n",
    "    # Range\n",
    "    range_var = df[column].max() - df[column].min()\n",
    "    print(f\"Range: {range_var}\")\n",
    "\n",
    "    # Minimum and Maximum\n",
    "    min_var = df[column].min()\n",
    "    max_var = df[column].max()\n",
    "    print(f\"Min: {min_var}, Max: {max_var}\")\n",
    "\n",
    "    # Mean and Standard Deviation\n",
    "    mean_var = df[column].mean()\n",
    "    std_var = df[column].std()\n",
    "    variance_var = df[column].var()\n",
    "    print(f\"Mean: {mean_var}, Standard Deviation: {std_var}, Variance: {variance_var}\")\n",
    "\n",
    "    # Mode, Median, and Quartiles\n",
    "    mode_var = df[column].mode()[0]\n",
    "    median_var = df[column].median()\n",
    "    quartiles = df[column].quantile([0.25, 0.5, 0.75, 0.95])\n",
    "    print(f\"Mode: {mode_var}\")\n",
    "    print(f\"Median: {median_var}\")\n",
    "    print(f\"Quartiles:\\n25%: {quartiles[0.25]}, 50%: {quartiles[0.5]}, 75%: {quartiles[0.75]}, 95%: {quartiles[0.95]}\")\n",
    "\n",
    "    # Histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df[column], bins=30, kde=True)\n",
    "    plt.title(f'Histogram of {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "# List of numerical columns to analyze\n",
    "numerical_columns = [\n",
    "    'NVDA_Adj Close',\n",
    "    'Google_Adj Close',\n",
    "    'AMD_Adj Close',\n",
    "    'Qualcomm_Adj Close',\n",
    "    'Intel_Adj Close'\n",
    "]\n",
    "\n",
    "# Analyze each specified numeric variable\n",
    "for column in numerical_columns:\n",
    "    analyze_numeric_variable(merged_data, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8KNhDHczLzss",
   "metadata": {
    "id": "8KNhDHczLzss"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def drop_outliers(df, column):\n",
    "    # Calculate Q1, Q3, and IQR\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Identify outliers\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "\n",
    "    # Print information about the data before dropping outliers\n",
    "    print(f\"Number of rows before dropping outliers: {len(df)}\")\n",
    "    print(f\"Sample outlier values for {column}: {outliers[column].head()}\")\n",
    "\n",
    "    # Drop outliers\n",
    "    df.drop(outliers.index, inplace=True)\n",
    "\n",
    "    # Print information about the data after dropping outliers\n",
    "    print(f\"Number of rows after dropping outliers: {len(df)}\")\n",
    "\n",
    "# Assuming merged_data is already loaded\n",
    "drop_outliers(merged_data, 'NVDA_Adj Close')\n",
    "drop_outliers(merged_data, 'NVDA_High')\n",
    "drop_outliers(merged_data, 'NVDA_Low')\n",
    "drop_outliers(merged_data, 'NVDA_Open')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5pSvqgDKU0_6",
   "metadata": {
    "id": "5pSvqgDKU0_6"
   },
   "outputs": [],
   "source": [
    "analyze_numeric_variable(merged_data, 'Beginning Cash Position')\n",
    "# Forward fill NaN values\n",
    "merged_data['Beginning Cash Position'] = merged_data['Beginning Cash Position'].fillna(method='ffill')\n",
    "analyze_numeric_variable(merged_data, 'Beginning Cash Position')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mi_m5bltWJGJ",
   "metadata": {
    "id": "mi_m5bltWJGJ"
   },
   "outputs": [],
   "source": [
    "# Drop non-numeric columns\n",
    "merged_data_df = merged_data.select_dtypes(include='number')\n",
    "\n",
    "print(\"DataFrame with only numeric columns:\")\n",
    "print(merged_data_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FU-YnOanXL0V",
   "metadata": {
    "id": "FU-YnOanXL0V"
   },
   "outputs": [],
   "source": [
    "correlation_matrix = merged_data_df.corr()\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EsSQVuqKoNqr",
   "metadata": {
    "id": "EsSQVuqKoNqr"
   },
   "source": [
    "Detecting and Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0jESNeeojSU",
   "metadata": {
    "id": "b0jESNeeojSU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompt: remove outliers from the data for all variables\n",
    "\n",
    "def drop_outliers(df, column):\n",
    "    # Calculate Q1, Q3, and IQR\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Identify outliers\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "\n",
    "    # Print information about the data before dropping outliers\n",
    "    print(f\"Number of rows before dropping outliers: {len(df)}\")\n",
    "    print(f\"Sample outlier values for {column}: {outliers[column].head()}\")\n",
    "\n",
    "    # Drop outliers\n",
    "    df.drop(outliers.index, inplace=True)\n",
    "\n",
    "    # Print information about the data after dropping outliers\n",
    "    print(f\"Number of rows after dropping outliers: {len(df)}\")\n",
    "\n",
    "# Iterate over all numeric columns and remove outliers\n",
    "for column in merged_data.select_dtypes(include='number'):\n",
    "    drop_outliers(merged_data, column)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
